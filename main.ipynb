{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"PYARROW_IGNORE_TIMEZONE\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import findspark\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql.types import FloatType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET = True\n",
    "SPARK_CONNECT = False\n",
    "HOST = None\n",
    "\n",
    "if RESET:\n",
    "    os.environ.pop(\"SPARK_REMOTE\", None)\n",
    "    os.environ.pop(\"SPARK_CONNECT_MODE_ENABLED\", None)\n",
    "    try:\n",
    "        exec(\"spark.stop()\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "spark = None\n",
    "\n",
    "if SPARK_CONNECT:\n",
    "    HOST = \"localhost\"\n",
    "    spark = (\n",
    "        SparkSession.builder.remote(\"sc://localhost:15002\")\n",
    "        .appName(\"ResearchProject\")\n",
    "        .config(\"spark.driver.host\", HOST)\n",
    "        .config(\"spark.driver.port\", 51041)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "else:\n",
    "    HOST = \"192.168.1.122\"\n",
    "    spark = SparkSession.builder\n",
    "    spark._options.pop(\"spark.remote\", None)\n",
    "    spark = (\n",
    "        spark.master(\"spark://localhost:7077\")\n",
    "        .appName(\"ResearchProject\")\n",
    "        .config(\"spark.driver.host\", HOST)\n",
    "        .config(\"spark.driver.port\", \"51041\")\n",
    "        .config(\"spark.driver.maxResultSize\", 0)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    # make spark more efficient\n",
    "    prev = spark.conf.get(\"spark.sql.execution.arrow.pyspark.enabled\")\n",
    "    ps.set_option(\"compute.default_index_type\", \"distributed\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    f\"hdfs://{HOST}:8020/data/MHSVI2020_US_county.csv\",\n",
    "    header=True,\n",
    "    encoding=\"ISO-8859-1\",\n",
    ").pandas_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = df.head()\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\"ST\", \"STATE\", \"ST_ABBR\", \"COUNTY\"]\n",
    "\n",
    "cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "for col in cols:\n",
    "    is_int = True\n",
    "    for row in df[col].loc[0:5].to_list():\n",
    "        is_int &= row.isdigit()\n",
    "        if is_int:\n",
    "            break\n",
    "    if is_int:\n",
    "        df[col] = df[col].astype(\"int64\")\n",
    "    else:\n",
    "        df[col] = ps.to_numeric(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afam_df = df[\n",
    "    [\n",
    "        \"UNIQUE_ID\",\n",
    "        \"ST\",\n",
    "        \"STATE\",\n",
    "        \"ST_ABBR\",\n",
    "        \"COUNTY\",\n",
    "        \"FIPS\",\n",
    "        \"E_TOTPOP\",\n",
    "        \"E_AFAM\",\n",
    "        \"EP_AFAM\",\n",
    "        \"EP_HBURD\",\n",
    "        \"EP_NOHSDP\",\n",
    "        \"EP_POV150\",\n",
    "        \"EP_UNINSUR\",\n",
    "        \"EP_DISABL\",\n",
    "        \"EP_CROWD\",\n",
    "        \"EP_NOINT\",\n",
    "        \"R_HOSP\",\n",
    "        \"R_PHARM\",\n",
    "        \"R_URG\",\n",
    "        \"ER_DIAB\",\n",
    "        \"ER_RESPD\",\n",
    "        \"ER_OBES\",\n",
    "        \"R_CARDIO\",\n",
    "    ]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afam_df = afam_df[afam_df[\"EP_AFAM\"] >= 14.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(afam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = (\n",
    "    afam_df[\n",
    "        [\n",
    "            \"ER_DIAB\",  # outcomes\n",
    "            \"ER_RESPD\",\n",
    "            \"ER_OBES\",\n",
    "            \"R_CARDIO\",\n",
    "            \"EP_HBURD\",  # factors\n",
    "            \"EP_NOHSDP\",\n",
    "            \"EP_POV150\",\n",
    "            \"EP_UNINSUR\",\n",
    "            \"EP_DISABL\",\n",
    "            \"EP_CROWD\",\n",
    "            \"EP_NOINT\",\n",
    "            \"R_HOSP\",\n",
    "            \"R_PHARM\",\n",
    "            \"R_URG\",\n",
    "        ]\n",
    "    ]\n",
    "    .corr()\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "print(correlation_matrix.to_markdown())\n",
    "print(type(correlation_matrix))\n",
    "print(correlation_matrix[\"ER_DIAB\"][\"ER_DIAB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", center=0.0, linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Health Factors and Outcomes in Black Communities\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afam_percentage_state_df = df[[\"STATE\", \"E_TOTPOP\", \"E_AFAM\"]].copy()\n",
    "afam_percentage_state_df = afam_percentage_state_df.groupby(\"STATE\")[[\"E_TOTPOP\", \"E_AFAM\"]]\n",
    "afam_percentage_state_df = afam_percentage_state_df.apply(lambda x: x[\"E_AFAM\"].sum() / x[\"E_TOTPOP\"].sum())\n",
    "afam_percentage_state_df = afam_percentage_state_df.reset_index(name=\"ER_AFAM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afam_percentage_state_df.to_csv('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_count_state_df = (\n",
    "    afam_df[[\"STATE\",\"E_AFAM\",\"ER_DIAB\"]]\n",
    "    .groupby(\"STATE\")\n",
    "    [[\"E_AFAM\", \"ER_DIAB\"]]\n",
    "    .apply(lambda x: sum(x[\"E_AFAM\"] * x[\"ER_DIAB\"]))\n",
    "    .reset_index(name=\"E_AFAM_DIAB\")\n",
    ")\n",
    "\n",
    "# print(diab_count_state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respd_count_state_d = (\n",
    "    afam_df[[\"STATE\",\"E_AFAM\",\"ER_RESPD\"]]\n",
    "    .groupby(\"STATE\")\n",
    "    [[\"E_AFAM\", \"ER_RESPD\"]]\n",
    "    .apply(lambda x: sum(x[\"E_AFAM\"] * x[\"ER_RESPD\"]))\n",
    "    .reset_index(name=\"E_AFAM_RESPD\")\n",
    ")\n",
    "\n",
    "print(respd_count_state_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obes_count_state_df = (\n",
    "    afam_df[[\"STATE\",\"E_AFAM\",\"ER_OBES\"]]\n",
    "    .groupby(\"STATE\")\n",
    "    [[\"E_AFAM\", \"ER_OBES\"]]\n",
    "    .apply(lambda x: sum(x[\"E_AFAM\"] * x[\"ER_OBES\"]))\n",
    "    .reset_index(name=\"E_AFAM_OBES\")\n",
    ")\n",
    "\n",
    "print(obes_count_state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_count_state_df = (\n",
    "    afam_df[[\"STATE\",\"E_AFAM\",\"R_CARDIO\"]]\n",
    "    .groupby(\"STATE\")\n",
    "    [[\"E_AFAM\", \"R_CARDIO\"]]\n",
    "    .apply(lambda x: sum(x[\"E_AFAM\"] * x[\"R_CARDIO\"]))\n",
    "    .reset_index(name=\"E_AFAM_CARDIO\")\n",
    ")\n",
    "\n",
    "print(cardio_count_state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame for heat map\n",
    "heat_map_data = {\n",
    "    \"state\": [\"California\", \"Texas\", \"New York\", \"Florida\", \"Illinois\"],\n",
    "    \"value\": [100, 90, 80, 70, 60],\n",
    "}\n",
    "df_heat_map = pd.DataFrame(heat_map_data)\n",
    "\n",
    "# Sample DataFrame for bubble map\n",
    "bubble_map_data = {\n",
    "    \"state\": [\"California\", \"Texas\", \"New York\", \"Florida\", \"Illinois\"],\n",
    "    \"bubble_value\": [50, 40, 30, 20, 10],\n",
    "}\n",
    "df_bubble_map = pd.DataFrame(bubble_map_data)\n",
    "\n",
    "# Load the US states shapefile\n",
    "states = gpd.read_file(\n",
    "    \"https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA.geo.json\"\n",
    ")\n",
    "\n",
    "# Rename the column to match the DataFrame\n",
    "states = states.rename(columns={\"name\": \"state\"})\n",
    "\n",
    "# Merge the DataFrame with the GeoDataFrame for heat map\n",
    "merged_heat_map = states.set_index(\"state\").join(df_heat_map.set_index(\"state\"))\n",
    "\n",
    "# Initialize the map centered on the US\n",
    "m = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "# Add a heat map layer\n",
    "folium.Choropleth(\n",
    "    geo_data=states,\n",
    "    name=\"choropleth\",\n",
    "    data=merged_heat_map,\n",
    "    columns=[merged_heat_map.index, \"value\"],\n",
    "    key_on=\"feature.properties.state\",\n",
    "    fill_color=\"YlOrRd\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Value by State\",\n",
    ").add_to(m)\n",
    "\n",
    "# Get state centroid coordinates for bubble map\n",
    "state_coordinates = {\n",
    "    \"California\": [36.7783, -119.4179],\n",
    "    \"Texas\": [31.9686, -99.9018],\n",
    "    \"New York\": [40.7128, -74.0060],\n",
    "    \"Florida\": [27.9944, -81.7603],\n",
    "    \"Illinois\": [40.6331, -89.3985],\n",
    "}\n",
    "\n",
    "state_coordinates = {\n",
    "    \"Alabama\": (32.806671, -86.79113),\n",
    "    \"Alaska\": (61.370716, -152.404419),\n",
    "    \"Arizona\": (33.729759, -111.431221),\n",
    "    \"Arkansas\": (34.969704, -92.373123),\n",
    "    \"California\": (36.116203, -119.681564),\n",
    "    \"Colorado\": (39.059811, -105.311104),\n",
    "    \"Connecticut\": (41.597782, -72.755371),\n",
    "    \"Delaware\": (39.318523, -75.507141),\n",
    "    \"Florida\": (27.766279, -81.686783),\n",
    "    \"Georgia\": (33.040619, -83.643074),\n",
    "    \"Hawaii\": (21.094318, -157.498337),\n",
    "    \"Idaho\": (44.240459, -114.478828),\n",
    "    \"Illinois\": (40.349457, -88.986137),\n",
    "    \"Indiana\": (39.849426, -86.258278),\n",
    "    \"Iowa\": (42.011539, -93.210526),\n",
    "    \"Kansas\": (38.5266, -96.726486),\n",
    "    \"Kentucky\": (37.66814, -84.670067),\n",
    "    \"Louisiana\": (31.169546, -91.867805),\n",
    "    \"Maine\": (44.693947, -69.381927),\n",
    "    \"Maryland\": (39.063946, -76.802101),\n",
    "    \"Massachusetts\": (42.230171, -71.530106),\n",
    "    \"Michigan\": (43.326618, -84.536095),\n",
    "    \"Minnesota\": (45.694454, -93.900192),\n",
    "    \"Mississippi\": (32.741646, -89.678696),\n",
    "    \"Missouri\": (38.456085, -92.288368),\n",
    "    \"Montana\": (46.921925, -110.454353),\n",
    "    \"Nebraska\": (41.12537, -98.268082),\n",
    "    \"Nevada\": (38.313515, -117.055374),\n",
    "    \"New Hampshire\": (43.452492, -71.563896),\n",
    "    \"New Jersey\": (40.298904, -74.521011),\n",
    "    \"New Mexico\": (34.840515, -106.248482),\n",
    "    \"New York\": (42.165726, -74.948051),\n",
    "    \"North Carolina\": (35.630066, -79.806419),\n",
    "    \"North Dakota\": (47.528912, -99.784012),\n",
    "    \"Ohio\": (40.388783, -82.764915),\n",
    "    \"Oklahoma\": (35.565342, -96.928917),\n",
    "    \"Oregon\": (44.572021, -122.070938),\n",
    "    \"Pennsylvania\": (40.590752, -77.209755),\n",
    "    \"Rhode Island\": (41.680893, -71.51178),\n",
    "    \"South Carolina\": (33.856892, -80.945007),\n",
    "    \"South Dakota\": (44.299782, -99.438828),\n",
    "    \"Tennessee\": (35.747845, -86.692345),\n",
    "    \"Texas\": (31.054487, -97.563461),\n",
    "    \"Utah\": (40.150032, -111.862434),\n",
    "    \"Vermont\": (44.045876, -72.710686),\n",
    "    \"Virginia\": (37.769337, -78.169968),\n",
    "    \"Washington\": (47.400902, -121.490494),\n",
    "    \"West Virginia\": (38.491226, -80.954063),\n",
    "    \"Wisconsin\": (44.268543, -89.616508),\n",
    "    \"Wyoming\": (42.755966, -107.30249),\n",
    "}\n",
    "\n",
    "\n",
    "df_bubble_map[\"lat\"] = df_bubble_map[\"state\"].map(lambda x: state_coordinates[x][0])\n",
    "df_bubble_map[\"lon\"] = df_bubble_map[\"state\"].map(lambda x: state_coordinates[x][1])\n",
    "\n",
    "# Add bubble map layer\n",
    "for _, row in df_bubble_map.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"lat\"], row[\"lon\"]],\n",
    "        radius=row[\"bubble_value\"] / 10,  # Adjust size as needed\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        fill_color=\"blue\",\n",
    "        fill_opacity=0.6,\n",
    "        popup=row[\"state\"],\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "m.save(\"combined_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save as CSV\n",
    "output_path = f\"hdfs://{HOST}:8020/results/temp\"\n",
    "df.to_csv(output_path, header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
